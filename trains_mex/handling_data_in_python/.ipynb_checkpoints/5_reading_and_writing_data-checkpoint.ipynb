{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `os` module\n",
    "\"This module provides a portable way of using operating system dependent functionality\" such as setting the current working directory and other methods for accessing the filesystem.\n",
    "\n",
    "https://docs.python.org/3/library/os.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aditya/trainings/handling_data_in_python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python_types.png',\n",
       " 'conda_logo.svg',\n",
       " 'test_file.png',\n",
       " 'pycharm_screenshot.jpg',\n",
       " 'spyder_logo.png',\n",
       " 'vis_landscape.jpg',\n",
       " 'spyder_screenshot.png',\n",
       " 'python-logo.png',\n",
       " 'anaconda_logo.png',\n",
       " 'MuliIndexDataFrame.png',\n",
       " 'matplotlib_anatomy.webp',\n",
       " 'pycharm_logo.png']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('img')  # change the working directory\n",
    "os.listdir()  # execute the 'ls' command: list files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4_advanced_methods_and_descriptive_statistics_with_pandas.ipynb',\n",
       " 'jsonfile.json',\n",
       " '6_visualization_with_matplotlib_and_pandas.ipynb',\n",
       " 'img_ML',\n",
       " '3_introduction_to_numpy_and_pandas.ipynb',\n",
       " 'data',\n",
       " '7_introduction_to_ML.ipynb',\n",
       " 'textfile.txt',\n",
       " '5_reading_and_writing_data.ipynb',\n",
       " '1_data_structures_in_python.ipynb',\n",
       " 'img',\n",
       " '2_control_flows.ipynb',\n",
       " 'picklefile.pickle',\n",
       " '0_introduction.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')  # go one directory up\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4_advanced_methods_and_descriptive_statistics_with_pandas.ipynb',\n",
       " 'jsonfile.json',\n",
       " '6_visualization_with_matplotlib_and_pandas.ipynb',\n",
       " 'img_ML',\n",
       " 'test_dir',\n",
       " '3_introduction_to_numpy_and_pandas.ipynb',\n",
       " 'data',\n",
       " '7_introduction_to_ML.ipynb',\n",
       " 'textfile.txt',\n",
       " '5_reading_and_writing_data.ipynb',\n",
       " '1_data_structures_in_python.ipynb',\n",
       " 'img',\n",
       " '2_control_flows.ipynb',\n",
       " 'picklefile.pickle',\n",
       " '0_introduction.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.mkdir('test_dir')  # create a folder\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4_advanced_methods_and_descriptive_statistics_with_pandas.ipynb',\n",
       " 'jsonfile.json',\n",
       " '6_visualization_with_matplotlib_and_pandas.ipynb',\n",
       " 'img_ML',\n",
       " '3_introduction_to_numpy_and_pandas.ipynb',\n",
       " 'data',\n",
       " '7_introduction_to_ML.ipynb',\n",
       " 'textfile.txt',\n",
       " '5_reading_and_writing_data.ipynb',\n",
       " '1_data_structures_in_python.ipynb',\n",
       " 'img',\n",
       " '2_control_flows.ipynb',\n",
       " 'test_dir_new_name',\n",
       " 'picklefile.pickle',\n",
       " '0_introduction.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.rename('test_dir', 'test_dir_new_name')  # rename a file or folder\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4_advanced_methods_and_descriptive_statistics_with_pandas.ipynb',\n",
       " 'jsonfile.json',\n",
       " '6_visualization_with_matplotlib_and_pandas.ipynb',\n",
       " 'img_ML',\n",
       " '3_introduction_to_numpy_and_pandas.ipynb',\n",
       " 'data',\n",
       " '7_introduction_to_ML.ipynb',\n",
       " 'textfile.txt',\n",
       " '5_reading_and_writing_data.ipynb',\n",
       " '1_data_structures_in_python.ipynb',\n",
       " 'img',\n",
       " '2_control_flows.ipynb',\n",
       " 'picklefile.pickle',\n",
       " '0_introduction.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.removedirs('test_dir_new_name')  # delete a folder\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `os.path` module\n",
    "\"This module implements some useful functions on pathnames.\"\n",
    "\n",
    "\n",
    "\"The path parameters can be passed as either strings, or bytes. Applications are encouraged to represent file names as (Unicode) character strings. Unfortunately, some file names may not be representable as strings on Unix, so applications that need to support arbitrary file names on Unix should use bytes objects to represent path names. Vice versa, using bytes objects cannot represent all file names on Windows (in the standard mbcs encoding), hence Windows applications should use string objects to access all files.\"\n",
    "\n",
    "https://docs.python.org/3/library/os.path.html\n",
    "\n",
    "Many methods accept *path-like objects* as input:\n",
    "\"**path-like object:** An object representing a file system path. A path-like object is either a ```str``` or ```bytes``` object representing a path, or an object implementing the ```os.PathLike``` protocol. An object that supports the ```os.PathLike``` protocol can be converted to a ```str``` or ```bytes``` file system path by calling the ```os.fspath()``` function; ```os.fsdecode()``` and ```os.fsencode()``` can be used to guarantee a ```str``` or ```bytes``` result instead, respectively. Introduced by PEP 519.\"\n",
    "\n",
    "https://docs.python.org/3/glossary.html#term-path-like-object\n",
    "\n",
    "The following cells introduce some basic functions. See https://docs.python.org/3/library/os.path.html for a complete list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dan/git/u42/trainings/handling_data_in_python'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a given object is a directory\n",
    "os.path.isdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dan/git/u42/trainings'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the name of the directory\n",
    "os.path.dirname(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dan/git/u42/trainings/handling_data_in_python/5_reading_and_writing_data.ipynb'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine a directory and a file name\n",
    "current_file = os.path.join(current_dir, \n",
    "                            '5_reading_and_writing_data.ipynb')\n",
    "current_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a file exists\n",
    "os.path.isfile(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a directory exists\n",
    "os.path.exists(os.path.join(current_dir, 'img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dan/git/u42/trainings/handling_data_in_python/img'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the canonical path of the specified filename, eliminating any symbolic links \n",
    "# encountered in the path (if they are supported by the operating system).\n",
    "\n",
    "os.path.realpath('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dan/git/u42/trainings/handling_data_in_python/img'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a normalized absolutized version of the pathname path. \n",
    "# On most platforms, this is equivalent to calling the function normpath() as follows:\n",
    "# normpath(join(os.getcwd(), path)).\n",
    "\n",
    "os.path.abspath('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize a pathname by collapsing redundant separators and up-level references \n",
    "# so that A//B, A/B/, A/./B and A/foo/../B all become A/B. \n",
    "# This string manipulation may change the meaning of a path that contains symbolic links. \n",
    "# On Windows, it converts forward slashes to backward slashes.\n",
    "\n",
    "os.path.normpath('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'handling_data_in_python'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the basename of a directory\n",
    "os.path.basename(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/dan/git/u42/trainings/handling_data_in_python',\n",
       " '5_reading_and_writing_data.ipynb')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split file into directory path and file name\n",
    "os.path.split(current_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `with` statement\n",
    "\"The with statement is used to wrap the execution of a block with methods defined by a context manager. This allows common `try…except…finally` usage patterns to be encapsulated for convenient reuse.\"\n",
    "The context manager defines `__exit__()` and `__enter__()` methods.\n",
    "\n",
    "After running the code in the with statement, a clean up process is executed. \" The `with` statement guarantees that if the `__enter__()` method returns without an error, then `__exit__()` will always be called\"\n",
    "\n",
    "This is often used when working with files as described in the next section.\n",
    "\n",
    "https://docs.python.org/3/reference/compound_stmts.html#the-with-statement\n",
    "\n",
    "https://www.python.org/dev/peps/pep-0343/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`with expression as variable:\n",
    "    with-block`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Files\n",
    "This section describes how to read and write files (e.g. CSV files). The full documentation of reading and writing files with Python 3 can be found at https://docs.python.org/3/tutorial/inputoutput.html.\n",
    "\n",
    "\n",
    "## The `open()` method\n",
    "\"`open()` returns a file object, and is most commonly used with two arguments: `open(filename, mode)`.\"\n",
    "Mode can be one of the following:\n",
    "* `'r'`: only reading (default)\n",
    "* `'w'`: only writing (overwrites existing file)\n",
    "* `'a'`: appending\n",
    "* `'r+'`: reading and writing\n",
    "\n",
    "Appending `'b'` to the mode \"opens the file in *binary mode*\" that \"should be used for all files that don't contain text\".\n",
    "\n",
    "https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files\n",
    "\n",
    "\n",
    "## Methods of File Objects\n",
    "\n",
    "* `read(size)`: reads `size` bytes of the file (`size` by default reads the entire file into memory)\n",
    "* `readline()`: \"reads a single line\"\n",
    "* `write(string)`: :writes content of *string* to the file\"\n",
    "\n",
    "https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'textfile.txt'\n",
    "\n",
    "f = open(filename, 'w')\n",
    "f.write('my first line\\n')\n",
    "f.write('second line')\n",
    "f.close()  # close file and free up system resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my first line\n",
      "second line\n"
     ]
    }
   ],
   "source": [
    "f = open(filename, 'r')\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my first line\n",
      "\n",
      "second line\n"
     ]
    }
   ],
   "source": [
    "f = open(filename, 'r')\n",
    "print(f.readline())\n",
    "print(f.readline())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my first line\n",
      "\n",
      "second line\n"
     ]
    }
   ],
   "source": [
    "f = open(filename, 'r')\n",
    "for line in f:\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my first line\n",
      "second line\n"
     ]
    }
   ],
   "source": [
    "# Better: use the with statement to close the files automatically\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `json` Module\n",
    "* \"The standard module called `json` can take Python data hierarchies, and convert them to string representations; this process is called *serializing*.\"\n",
    "* \"Reconstructing the data from the string representation is called *deserializing*.\"\n",
    "* \"Between *serializing* and *deserializing*, the string representing the object may have been stored in a file or data, or sent over a network connection to some distant machine.\"\n",
    "\n",
    "https://docs.python.org/3.3/tutorial/inputoutput.html#saving-structured-data-with-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, \"simple\", \"list\"]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# convert an object to its JSON string representation\n",
    "x = [1, 'simple', 'list']\n",
    "json.dumps(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize an object to a text file\n",
    "jsonfile = 'jsonfile.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'simple', 'list']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(jsonfile, 'r') as f:\n",
    "    j = json.load(f)  # read a JSON file from disk\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Files with pandas\n",
    "pandas can be used to read many formats such as CSV, Excel, JSON, Parquet, SQL, HDF, and many more. A full list of methods to read data is provided at http://pandas.pydata.org/pandas-docs/stable/reference/io.html. \n",
    "\n",
    "### Writing CSV\n",
    "\n",
    "\"Write object to a comma-separated values (csv) file.\"\n",
    "\n",
    "```DataFrame.to_csv(path_or_buf=None, sep=', ', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', line_terminator=None, chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')```\n",
    "\n",
    "\"**Parameters:**\n",
    "* **path_or_buf:** *str or file handle, default ```None```.* File path or object, if ```None``` is provided the result is returned as a string. If a file object is passed it should be opened with ```newline=’‘```, disabling universal newlines.\n",
    "* **sep:** *str, default ‘,’.* String of length 1. Field delimiter for the output file.\n",
    "* **na_rep:** *str, default ‘’.* Missing data representation.\n",
    "* **float_format:** *str, default None.* Format string for floating point numbers.\n",
    "* **columns:** *sequence, optional.* Columns to write.\n",
    "* **header:** *bool or list of str, default ```True```.* Write out the column names. If a list of strings is given it is assumed to be aliases for the column names.\n",
    "* **index:** *bool, default ```True```.* Write row names (index).\n",
    "* ...\n",
    "\n",
    "**Returns: ```None``` or str.** If path_or_buf is ```None```, returns the resulting csv format as a string. Otherwise returns ```None```.\"\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# create a DataFrame\n",
    "df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
    "                   'mask': ['red', 'purple'],\n",
    "                   'weapon': ['sai', 'bo staff']})\n",
    "# write the DataFrame to disk\n",
    "df.to_csv('data/turtles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mask</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raphael</td>\n",
       "      <td>red</td>\n",
       "      <td>sai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donatello</td>\n",
       "      <td>purple</td>\n",
       "      <td>bo staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name    mask    weapon\n",
       "0    Raphael     red       sai\n",
       "1  Donatello  purple  bo staff"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV\n",
    "\n",
    "\"Read a comma-separated values (csv) file into DataFrame. Also supports optionally iterating or breaking of the file into chunks. Additional help can be found in the online docs for IO Tools.\"\n",
    "\n",
    "```pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)```\n",
    "\n",
    "\n",
    "\"**Parameters:**\n",
    "* **filepath_or_buffer:** *str, path object, or file-like object*. Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. If you want to pass in a path object, pandas accepts either ```pathlib.Path``` or ```py._path.local.LocalPath```. By file-like object, we refer to objects with a ```read()``` method, such as a file handler (e.g. via builtin open function) or ```StringIO```.\n",
    "* **sep:** *str, default ‘,’*. Delimiter to use. If sep is ```None```, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python’s builtin sniffer tool, ```csv.Sniffer```. In addition, separators longer than 1 character and different from ```'\\s+'``` will be interpreted as regular expressions and will also force the use of the Python parsing engine. Note that regex delimiters are prone to ignoring quoted data. Regex example: ```'\\r\\t'```.\n",
    "* **delimiter:** *str, default ```None```*. Alias for sep.\n",
    "* ...\n",
    "\n",
    "**Returns: DataFrame or TextParser**. A comma-separated values (csv) file is returned as two-dimensional data structure with labeled axes.\"\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mask</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raphael</td>\n",
       "      <td>red</td>\n",
       "      <td>sai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donatello</td>\n",
       "      <td>purple</td>\n",
       "      <td>bo staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name    mask    weapon\n",
       "0    Raphael     red       sai\n",
       "1  Donatello  purple  bo staff"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read a csv file from disk\n",
    "pd.read_csv('data/turtles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Excel\n",
    "\n",
    "\"Write object to an Excel sheet. To write a single object to an Excel *.xlsx* file it is only necessary to specify a target file name. To write to multiple sheets it is necessary to create an ```ExcelWriter``` object with a target file name, and specify a sheet in the file to write to. Multiple sheets may be written to by specifying unique ```sheet_name```. With all data written to the file it is necessary to save the changes. Note that creating an ```ExcelWriter``` object with a file name that already exists will result in the contents of the existing file being erased.\"\n",
    "\n",
    "```DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)```\n",
    "\n",
    "\"**Parameters:**\n",
    "* **excel_writer:** *str or ```ExcelWriter``` object*. File path or existing ```ExcelWriter```.\n",
    "* **sheet_name:** *str, default ‘Sheet1’*. Name of sheet which will contain DataFrame.\n",
    "* **na_rep:** *str, default ‘’*. Missing data representation.\n",
    "* **float_format:** *str, optional*. Format string for floating point numbers. For example ```float_format=\"%.2f\"``` will format 0.1234 to 0.12.\n",
    "* **columns:** *sequence or list of str, optional*. Columns to write.\n",
    "* **header:** *bool or list of str, default True*. Write out the column names. If a list of string is given it is assumed to be aliases for the column names.\n",
    "* **index:** *bool, default ```True```*. Write row names (index).\n",
    "* **index_label:** *str or sequence, optional*. Column label for index column(s) if desired. If not specified, and header and index are ```True```, then the index names are used. A sequence should be given if the DataFrame uses ```MultiIndex```.\n",
    "* ...\"\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DataFrame in .xlsx format to disk\n",
    "df.to_excel('data/turtles.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Excel\n",
    "\n",
    "\"Read an Excel file into a pandas DataFrame.\n",
    "\n",
    "Support both *xls* and *xlsx* file extensions from a local filesystem or URL. Support an option to read a single sheet or a list of sheets.\"\n",
    "\n",
    "```pandas.read_excel(io, sheet_name=0, header=0, names=None, index_col=None, parse_cols=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skip_footer=0, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)```\n",
    "\n",
    "\"**Parameters:**\n",
    "* **io:** *str, file descriptor, pathlib.Path, ExcelFile or xlrd.Book*. The string could be a URL. Valid URL schemes include http, ftp, s3, gcs, and file. For file URLs, a host is expected. For instance, a local file could be /path/to/workbook.xlsx.\n",
    "* **sheet_name:** *str, int, list, or ```None```, default 0*. Strings are used for sheet names. Integers are used in zero-indexed sheet positions. Lists of strings/integers are used to request multiple sheets. Specify ```None``` to get all sheets. Available cases:\n",
    "  * Defaults to 0: 1st sheet as a DataFrame\n",
    "  * 1: 2nd sheet as a DataFrame\n",
    "  * \"Sheet1\": Load sheet with name “Sheet1”\n",
    "  * [0, 1, \"Sheet5\"]: Load first, second and sheet named “Sheet5” as a dict of DataFrame\n",
    "  * ```None```: All sheets.\n",
    "* **header:** *int, list of int, default 0*. Row (0-indexed) to use for the column labels of the parsed DataFrame. If a list of integers is passed those row positions will be combined into a ```MultiIndex```. Use ```None``` if there is no header.\n",
    "* **names:** *array-like, default ```None```*. List of column names to use. If file contains no header row, then you should explicitly pass ```header=None```.\n",
    "* ...\n",
    "\n",
    "**Returns: DataFrame or dict of DataFrames**. DataFrame from the passed in Excel file. See notes in ```sheet_name``` argument for more information on when a dict of DataFrames is returned.\"\n",
    "`\n",
    "http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>mask</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Raphael</td>\n",
       "      <td>red</td>\n",
       "      <td>sai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Donatello</td>\n",
       "      <td>purple</td>\n",
       "      <td>bo staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       name    mask    weapon\n",
       "0           0    Raphael     red       sai\n",
       "1           1  Donatello  purple  bo staff"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read excel file from disk\n",
    "pd.read_excel('data/turtles.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing JSON\n",
    "\n",
    "\"Convert the object to a JSON string. Note ```NaN```’s and ```None``` will be converted to null and datetime objects will be converted to UNIX timestamps.\"\n",
    "\n",
    "```DataFrame.to_json(path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=True)```\n",
    "\n",
    "\"**Parameters:**\n",
    "* **path_or_buf:** *string or file handle, optional*. File path or object. If not specified, the result is returned as a string.\n",
    "* **orient:** *string*. Indication of expected JSON string format.\n",
    "  * Series\n",
    "    * default is ‘index’\n",
    "    * allowed values are: {‘split’,’records’,’index’,’table’}\n",
    "  * DataFrame\n",
    "    * default is ‘columns’\n",
    "    * allowed values are: {‘split’,’records’,’index’,’columns’,’values’,’table’}\n",
    "  * The format of the JSON string\n",
    "    * ‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values]}\n",
    "    * ‘records’ : list like [{column -> value}, … , {column -> value}]\n",
    "    * ‘index’ : dict like {index -> {column -> value}}\n",
    "    * ‘columns’ : dict like {column -> {index -> value}}\n",
    "    * ‘values’ : just the values array\n",
    "    * ‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}} describing the data, and the data component is like orient='records'.\n",
    "* ...\"\n",
    "\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DataFrame to disk with records indication \n",
    "df.to_json('data/turtles.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON\n",
    "\n",
    "\"Convert a JSON string to pandas object.\"\n",
    "\n",
    "```pandas.read_json(path_or_buf=None, orient=None, typ='frame', dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=False, precise_float=False, date_unit=None, encoding=None, lines=False, chunksize=None, compression='infer')```\n",
    "\n",
    "\"**Parameters:**\n",
    "* **path_or_buf:** *a valid JSON string or file-like, default: ```None```*. The string could be a URL. Valid URL schemes include http, ftp, s3, gcs, and file. For file URLs, a host is expected. For instance, a local file could be file://localhost/path/to/table.json\n",
    "* **orient:** *string*. Indication of expected JSON string format. Compatible JSON strings can be produced by ```to_json()``` with a corresponding orient value. The set of possible orients is:\n",
    "  * 'split' : dict like {index -> [index], columns -> [columns], data -> [values]}\n",
    "  * 'records' : list like [{column -> value}, ... , {column -> value}]\n",
    "  * 'index' : dict like {index -> {column -> value}}\n",
    "  * 'columns' : dict like {column -> {index -> value}}\n",
    "  * 'values' : just the values array\n",
    "\n",
    "  The allowed and default values depend on the value of the typ parameter.\n",
    "  * when typ == 'series',\n",
    "    * allowed orients are {'split','records','index'}\n",
    "    * default is 'index'\n",
    "    * The Series index must be unique for orient 'index'.\n",
    "  * when typ == 'frame',\n",
    "    * allowed orients are {'split','records','index', 'columns','values', 'table'}\n",
    "    * default is 'columns'\n",
    "    * The DataFrame index must be unique for orients 'index' and 'columns'.\n",
    "    * The DataFrame columns must be unique for orients 'index', 'columns', and 'records'.\n",
    "* ...\n",
    "\n",
    "**Returns: result:** *Series or DataFrame*, depending on the value of typ.\"\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mask</th>\n",
       "      <th>name</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>Raphael</td>\n",
       "      <td>sai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>Donatello</td>\n",
       "      <td>bo staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mask       name    weapon\n",
       "0     red    Raphael       sai\n",
       "1  purple  Donatello  bo staff"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json from disk\n",
    "pd.read_json('data/turtles.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling\n",
    "* \"The `pickle` module implements binary protocols for serializing and de-serializing a Python object structure.\"\n",
    "* \"*Pickling* is the process whereby a Python object hierarchy is converted into a byte stream, and *unpickling* is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy.\"\n",
    "* \"*Pickling* (and *unpickling*) is alternatively known as “serialization”, “marshalling,” or “flattening”.\"\n",
    "\n",
    "https://docs.python.org/3.3/library/pickle.html#module-pickle\n",
    "\n",
    "## Pickle vs JSON\n",
    "\n",
    "| -                     | Pickle | JSON               |\n",
    "|:----------------------|:-------|:-------------------|\n",
    "| Serialization         | Binary | Text               |\n",
    "| Human-readable        | No     | Yes                |\n",
    "| Python-specific       | Yes    | No (interoperable) |\n",
    "| Python build-in types | Yes    | No (default)       |\n",
    "| Custom classes        | Yes    | No                 |\n",
    "\n",
    "https://docs.python.org/3.3/library/pickle.html#comparison-with-json\n",
    "\n",
    "\n",
    "## What can be pickled and unpickled?\n",
    "* \"`None`, `True`, and `False`\n",
    "* integers, floating point numbers, complex numbers\n",
    "* strings, bytes, bytearrays\n",
    "* tuples, lists, sets, and dictionaries containing only picklable objects\n",
    "* functions defined at the top level of a module\n",
    "* built-in functions defined at the top level of a module\n",
    "* classes that are defined at the top level of a module\n",
    "* instances of such classes whose `__dict__` or the result of calling `__getstate__()` is picklable (see section [Pickling Class Instances](https://docs.python.org/3.3/library/pickle.html#pickle-inst) for details).\"\n",
    "\n",
    "`PicklingError` will be raised when trying to pickle unpickle objects.\n",
    "\n",
    "https://docs.python.org/3.3/library/pickle.html#what-can-be-pickled-and-unpickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'simple', 'list']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03]q\\x00(K\\x01X\\x06\\x00\\x00\\x00simpleq\\x01X\\x04\\x00\\x00\\x00listq\\x02e.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dumps(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklefile = 'picklefile.pickle'\n",
    "# open file in write and binary mode: 'wb'\n",
    "with open(picklefile, 'wb') as f:\n",
    "    pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'simple', 'list']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the file in read and binary mode\n",
    "with open(picklefile, 'rb') as f:\n",
    "    p = pickle.load(f)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `try` statement\n",
    "* \"The `try` statement specifies exception handlers and/or cleanup code for a group of statements\"\n",
    "* \"The `except` clause(s) specify one or more exception handlers. When no exception occurs in the `try` clause, no exception handler is executed\"`\n",
    "* \"An expression-less `except` clause, if present, must be last; it matches any exception\"\n",
    "* \"The optional `else` clause is executed if the control flow leaves the `try` suite, no exception was raised, and no `return`, `continue`, or `break` statement was executed\"\n",
    "* \"If `finally` is present, it specifies a ‘cleanup’ handler\"\n",
    "\n",
    "https://docs.python.org/3/reference/compound_stmts.html#the-try-statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "1/x=1.0 with x=1\n",
      "Finishing up...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    try:\n",
    "        print(\"Starting...\")\n",
    "        print(\"1/x={} with x={}\".format(1/x, x))\n",
    "        return x\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError raised...\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception: {}\".format(e))\n",
    "    finally:\n",
    "        print(\"Finishing up...\")\n",
    "f(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "ZeroDivisionError raised...\n",
      "Finishing up...\n"
     ]
    }
   ],
   "source": [
    "f(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Exception: unsupported operand type(s) for /: 'int' and 'str'\n",
      "Finishing up...\n"
     ]
    }
   ],
   "source": [
    "f('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More exceptions are documented at https://docs.python.org/3/tutorial/errors.html#exceptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
