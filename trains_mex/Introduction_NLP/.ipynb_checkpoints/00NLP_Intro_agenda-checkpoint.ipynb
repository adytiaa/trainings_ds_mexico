{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Natural Language Processing (NLP)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Outline of the course\n",
    "---------------\n",
    "\n",
    "* Statistical principles of NLP \n",
    "\n",
    "* Elements of NLP: computational representations (Entities, Tokens, Syntax, Lexions,...)\n",
    "\n",
    "* Important open-source NLP libraries: NLTK and SpaCy\n",
    "\n",
    "* Vectorial Representations (Word Embeddings)\n",
    "\n",
    "* NLP using Neural Networks \n",
    "\n",
    "* Applications of NLP: Chatbots, Sentiment analysis, Spam filtering,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction: Background\n",
    "\n",
    "\n",
    "What is NLP? \n",
    "-------------------\n",
    "* Natural Language Processing, or NLP, is an area of computer science that focuses on developing techniques to produce machine-driven analyses of text\n",
    "\n",
    "* In the broad field of artificial intelligence, the ability to parse and understand natural language is an important goal with many types of application \n",
    "\n",
    "* Text data is unstructured which needs formatting/engineering to analyse and obtain a mathematical representation \n",
    "\n",
    "* NLP began in the 1950s as the intersection of artificial intelligence and linguistics. NLP was originally distinct from text information retrieval (IR), which employs highly scalable statistics-based techniques to index and search large volumes of text efficiently\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why is Natural Language Processing Important? \n",
    "---------------------------------------------------------------------\n",
    "\n",
    "* NLP expands the sheer amount of data that can be used for insight. Since so much of the data available is in the form of text, this is extremely important for analytics and predictions \n",
    "\n",
    "* A specific common application of NLP is each time you use a language conversion tool. The techniques used to accurately convert text from one language to another very much falls under the umbrella of \"natural language processing.\"\n",
    "\n",
    "Why is NLP a \"hard\" problem?\n",
    "---------------------------------------------\n",
    "\n",
    "* Language is inherently ambiguous. Once person's interpretation of a sentence may very well differ from another person's interpretation. Because of this inability to consistently be clear, it's hard to have an NLP technique that works perfectly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLP and Computational Linguistics\n",
    "\n",
    "* There’s an area which is closely related to NLP and sometimes confused with it\n",
    "\n",
    "\n",
    "* Computational Linguistics is a more theoretical field that develops computational methods to answer the scientific questions from the point of view of linguists\n",
    "    \n",
    "    \n",
    "* Natural Language Processing is dedicated to give solutions to engineering problems related to natural language, focusing on the people\n",
    "\n",
    "\n",
    "*  \"CL is science\" and \"NLP is engineering\" is a nice distinction\n",
    "\n",
    "![](./data/cl.jpeg?raw=true)\n",
    "##### source: zipfslaw.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical NLP\n",
    "\n",
    "* Descriptive statistics is often used to provide the quantitative measurements of a particular quality such as accuracy or robustness, as exemplified in the following list\n",
    "\n",
    "* Word error rate, usually defined as the number of deletions, insertions and substitutions divided by the number of words in the test sample, is the standard measure of accuracy for automatic speech recognition systems\n",
    "\n",
    "* Accuracy rate (or percent correct), defined as the number of correct cases divided by the total number of cases, is commonly used as a measure of accuracy for part-of-speech tagging and word sense disambiguation \n",
    "\n",
    "* Recall and precision, often defined as the number of true positives divided by, respectively, the sum of true positives and false negatives (recall) and the sum of true positives and false positives (precision), are used as measures of accuracy for a wide range of applications including part-of-speech tagging, syntactic parsing and information retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Topics in NLP\n",
    "-------------------------\n",
    "* Computational linguistics\n",
    "* Statistical models\n",
    "* Neural networks\n",
    "* Elements of NLP: Computational Representations (Entities, Tokensiation, Syntax, Lexions)\n",
    "* Vector space embeddings\n",
    "* Pre-processing of data \n",
    "* Convolutional neural networks\n",
    "* RNNS: LSTMS and GRUs in practise\n",
    "* Advanced models:  Bi-directional LSTM and stacked LSTM\n",
    "* Hyper-parameter tuning\n",
    "* Applications of NLP: Chatbots, Sentiment analysis, Spam filtering, News flows classification\n",
    "* Important NLP libraries: NLTK, SpaCy, etc.\n",
    "* Text Classification: Linear classifiers, Naive bayes and deep learning technique\n",
    "* Information Retrieval and Extraction\n",
    "* Named entity recognition and Relationship extraction\n",
    "* Topic segmentation\n",
    "* Language Modeling and Sequence Tagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Implementations\n",
    "\n",
    "These are some of the successful implementation of Natural Language Processing (NLP):\n",
    "\n",
    "    Search engines like Google, Yahoo, etc. \n",
    "    \n",
    "    Social websites feeds like Facebook news feed where using NLP the algorithm understands and gives relevant     \n",
    "    suggestions \n",
    "    \n",
    "    Speech engines like Apple Siri\n",
    "    \n",
    "    Spam filters like Google ones which understand what’s inside the email content and check if its spam or not\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NLP Libraries \n",
    "-------------\n",
    "\n",
    "* There are many open source Natural Language Processing (NLP) libraries and these are some of them:\n",
    "\n",
    "                Natural language toolkit (NLTK)\n",
    "                \n",
    "                Apache OpenNLP\n",
    "                \n",
    "                Stanford NLP\n",
    "                \n",
    "                Gate NLP library\n",
    "                \n",
    "                Spacy library\n",
    "\n",
    "* Natural language toolkit (NLTK) is the most popular library for natural language processing (NLP) which was written in Python, very easy to learn, and is widely used for teaching and research [nltk](https://www.nltk.org/)\n",
    "\n",
    "* SpaCy, an open-source software library written in Python and Cython and offers statistical neural network models for English, German, Spanish, Portuguese, French, Italian, Dutch and multi-language Name-entity recognition (NER), as well as tokenisation for various other languages [Spacy](https://spacy.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Can NLP be used for ?\n",
    "\n",
    "* NLP algorithms are typically based on machine learning algorithms. Instead of hand-coding large sets of rules, NLP can rely on machine learning to automatically learn these rules by analysing a set of examples (i.e. a large corpus, like a book, down to a collection of sentences), and making a statical inferences. \n",
    "\n",
    "* Summarise blocks of text using Summariser to extract the most important and central ideas while ignoring irrelevant information. \n",
    "    \n",
    "* Create a chat bot and use Point-of-Speech tagging.\n",
    "   \n",
    "* Automatically generate keyword tags from content using probabilistic topic allocation algorithms (LDA)\n",
    "    \n",
    "* Identify the type of entity extracted, such as it being a person, place, or organization using Named Entity Recognition.\n",
    "    \n",
    "* Use Sentiment Analysis to identify the sentiment of a string of text, from very negative to neutral to very positive.\n",
    "    \n",
    "* Reduce words to their root, or stem, using PorterStemmer, or break up text into tokens using Tokenizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP related Tasks\n",
    "-------------------------\n",
    "\n",
    "* Spell and Grammar Checking\n",
    "\n",
    "* Word Prediction: Predicting the next word that is highly probable \n",
    "\n",
    "* Information retrieval (IR): give a word query, retrieve documents that are relevant to the query\n",
    "\n",
    "* Information filtering (text categorisation): group documents based on topics/categories\n",
    "– E.g. categories for browsing\n",
    "– E.g. E-mail filters\n",
    "– News services\n",
    "\n",
    "* Information extraction: given a text, get relevant information in a template. Closest to language understanding\n",
    "E.g. House advertisements (get location, price, features) or Contact information for companies\n",
    "\n",
    "![](./data/NLP-flowchart.png?raw=true)\n",
    "##### source: https://www.nltk.org/book/ch00.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Applications\n",
    "\n",
    "With NLP, we can do the following-\n",
    "\n",
    "    Summarising blocks of text\n",
    "    \n",
    "    Creating chatbots\n",
    "    \n",
    "    Machine translation\n",
    "    \n",
    "    Fighting spam\n",
    "    \n",
    "    Extracting information\n",
    "    \n",
    "    Automatically generating keyword tags\n",
    "    \n",
    "    Identifying types of entities extracted\n",
    "    \n",
    "    Identifying the sentiment of a string with sentiment analysis\n",
    "    \n",
    "    Reducing words to their roots\n",
    "    \n",
    "    Summarising \n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP at different levels of difficulties\n",
    "\n",
    "Easy (mostly solved)\n",
    "– Spell and grammar checking\n",
    "– Some text categorization tasks\n",
    "– Some named-entity recognition tasks\n",
    "\n",
    "\n",
    "Intermediate (good progress)\n",
    "– Information retrieval\n",
    "– Sentiment analysis\n",
    "– Machine translation\n",
    "– Information extraction\n",
    "\n",
    "\n",
    "\n",
    "Difficult (still hard)\n",
    "– Question answering\n",
    "– Summarization\n",
    "– Dialog systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks in NLP\n",
    "\n",
    "#### With Natural Language Processing, we carry out five different tasks\n",
    "\n",
    "* Lexical Analysis : Lexical analysis deals with identifying and analyzing word structure. We divide the whole chunk of text into paragraphs, sentences, and words\n",
    "\n",
    "* Syntactic Analysis: Also called parsing, it involves analyzing words in sentences for grammar and rearranging them to determine how they relate to each other. It rejects sentences like “The apple eats the girl”\n",
    "\n",
    "* Semantic Analysis: This deals with extracting the dictionary meanings from text. It also maps syntactic structures and objects in the task domain to check for meaningfulness. It rejects statements like “tall stub”\n",
    "\n",
    "* Discourse Integration: It analyzes the previous sentence to guess the meaning of the current sentence and the one after it\n",
    "\n",
    "* Pragmatic Analysis: This reinterprets the statement to ensure it determines correctly what the statement means. It tries to retrieve aspects of the language that requires knowledge of real world\n",
    "\n",
    "\n",
    "![](./data/nlp_task.jpeg?raw=true)\n",
    "##### source: Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Translation\n",
    "------------------------------\n",
    "\n",
    "* Translating a text from one language to another\n",
    "\n",
    "*  This need corpus statistical, and neural techniques which can give better translations, handling differences in linguistic typology, translation of idioms, and the isolation of anomalies\n",
    "\n",
    "![](./data/mt.gif?raw=true)\n",
    "##### source: Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Speech recognition\n",
    "--------------------------\n",
    "\n",
    "Speech to text\n",
    "\n",
    "• Input:  wave sound file\n",
    "\n",
    "• Output: typed text representing the words\n",
    "\n",
    "• To disambiguate  the  next  word,  one  can  use  sequence models  to  predict the most likely next word, based on the past words\n",
    "\n",
    "\n",
    "![](./data/sprec1.jpeg?raw=true)\n",
    "##### source: Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech recognition\n",
    "--------------------------\n",
    "\n",
    "Text to speech\n",
    "\n",
    "• Input: typed text representing the words\n",
    "\n",
    "• Output: wave sound file\n",
    "\n",
    "\n",
    "![](./data/tts.png?raw=true)\n",
    "##### source: Medium\n",
    "\n",
    "#### C: new picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis  \n",
    "-------------------\n",
    "\n",
    "* Sentiment analysis involves building a system to collect and determine the emotional tone behind words. \n",
    "\n",
    "* This is important because it allows you to gain an understanding of the attitudes, opinions and emotions of the people in your data. \n",
    "\n",
    " * It involves Natural language processing of the actual text element, transforming it into a format that a machine can read, and using statistics to determine the actual sentiment.\n",
    " \n",
    " * Important to have labelled Data to accomplish sentiment analysis computationally, we have to use techniques that will allow us to learn from data that's already been labeled\n",
    " \n",
    " ![](./data/senti.png?raw=true)\n",
    "##### source: Glue Labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Projects related to NLP applications \n",
    "\n",
    "Development of applications which carry out\n",
    "\n",
    "* Information Retrieval\n",
    "* Information Extraction\n",
    "* Text Summarization\n",
    "* Question Answering\n",
    "* Sentiment Analysis\n",
    "* Machine Translation\n",
    "\n",
    "\n",
    "These applications include the following components\n",
    "\n",
    "* Part-of-speech tagging\n",
    "* Syntactic parsing\n",
    "* Lexical semantics\n",
    "* Discourse analysis\n",
    "* Named-entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glossary of terms in NLP\n",
    "----------------------------\n",
    "\n",
    "\n",
    "Some common terminology\n",
    "\n",
    "<b>Corpus: </b> (Plural: Corpora) a collection of written texts that serve as our datasets\n",
    "\n",
    "<b>nltk: </b> (Natural Language Toolkit) the python module wich has a lot of useful built-in NLP techniques\n",
    "\n",
    "<b>Token: </b> a string of contiguous characters between two spaces, or between a space and punctuation marks. A token can also be an integer, real, or a number with a colon\n",
    "\n",
    "\n",
    "<b>Parts of speech Tagging: </b> process of tagging each word, into a lexical category: Noun, Adjective, Verb, etc...\n",
    "\n",
    "\n",
    "\n",
    "<b>WordNet:</b> A semantic graph for words. NLTK provides a interface to the API </li></h3>\n",
    "\n",
    "\n",
    "\n",
    "<b>Chunks: </b> Chunking is the process of collecting patterns of Part of Speech together, representing some meaning.\n",
    "\n",
    "\n",
    "<b>Entity Recognition - Chunking: </b> The goal is to detect entities: Person, Location, Time, etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Summary\n",
    "---------------------------------\n",
    "\n",
    "    Natural Language Processing is a branch of AI which helps computers to understand, interpret and manipulate human language\n",
    "    \n",
    "    NLP never focuses on voice modulation; it does draw on contextual patterns\n",
    "    \n",
    "    Five essential components of Natural Language processing are 1) Morphological and Lexical Analysis 2)Syntactic Analysis 3) Semantic Analysis 4) Discourse Integration 5) Pragmatic Analysis\n",
    "    \n",
    "    Three types of the Natural process writing system are 1)Logographic 2) Syllabic 3) Alphabetic\n",
    "    \n",
    "    Machine learning and Statistical inference are two methods to implementation of Natural Process Learning\n",
    "    \n",
    "    Essential Applications of NLP are Information retrieval & Web Search, Grammar Correction Question Answering, Text Summarization, Machine Translation, etc.\n",
    "    \n",
    "    Future computers or machines with the help of NLP and Data Science will able to learn from the information online and apply that in the real world, however, lots of work need to on this regard\n",
    "    \n",
    "    NLP is are ambiguous while open source computer language is designed to unambiguous. The biggest advantage of the NLP system is that it offers exact answers to the questions, no unnecessary or unwanted information\n",
    "    \n",
    "    \n",
    "    The biggest draw back of the NLP system is built for a single and specific task only so it is unable to adapt to new domains and problems because of limited functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks in NLP\n",
    "--------------------\n",
    "\n",
    "With Natural Language Processing, five different tasks\n",
    "\n",
    "a. Lexical Analysis: deals with identifying and analyzing word structure the whole chunk of text into paragraphs, sentences, and words\n",
    "\n",
    "b. Syntactic Analysis or Parsing: involves analysing words in sentences for grammar and rearranging them to determine how they relate to each other\n",
    "\n",
    "\n",
    "c. Semantic Analysis: This deals with extracting the dictionary meanings from text. It also maps syntactic structures and objects in the task domain to check for meaningfulness. It rejects statements like “tall stub”.\n",
    "\n",
    "\n",
    "d. Discourse Integration: It analyzes the previous sentence to guess the meaning of the current sentence and the one after it.\n",
    "\n",
    "\n",
    "e. Pragmatic Analysis: This reinterprets the statement to ensure it determines correctly what the statement means. It tries to retrieve aspects of the language that requires knowledge of real world\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next steps\n",
    "\n",
    "\n",
    "### Statistical NLP \n",
    "\n",
    "### NLTK tutorial\n",
    "\n",
    "### Advanced NLP tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
